{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from tensorflow import keras\n",
    "### hack tf-keras to appear as top level keras\n",
    "import sys\n",
    "sys.modules['keras'] = keras\n",
    "### end of hack\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, callbacks\n",
    "from keras.callbacks import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import pprint\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "\n",
    "# Importing custom framework\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from data_split import prepare_data_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(227, (3, 1), activation='relu', input_shape=(1, 227, 227), data_format='channels_first'))\n",
    "    model.add(layers.MaxPooling2D((3, 1), 2))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 1), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 1), 2))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 1), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 1), 2))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 1), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 1), 2))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 1), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 1), 2))\n",
    "    \n",
    "    #Fully Connected Part\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(1024))#, input_dim=1024\n",
    "    model.add(layers.Dropout(0.5, seed=1337))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.Dense(512))#, input_dim=1024\n",
    "    model.add(layers.Dropout(0.5, seed=1337))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.Dense(10, input_dim=512))\n",
    "    model.add(layers.Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogramPath = '../../merged/spectrogram.hdf5'\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = prepare_data_spectrogram(spectrogramPath, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1, 227, 227)\n"
     ]
    }
   ],
   "source": [
    "# Decrease training data size to make training feasable\n",
    "X_temp = []\n",
    "y_temp = []\n",
    "n = 300\n",
    "count_dict = dict.fromkeys(range(0, 10), 0)\n",
    "for i in range(len(y_train)):\n",
    "    curr = y_train[i]\n",
    "    if count_dict[curr] >= n:\n",
    "        finished = True\n",
    "        for x in count_dict.values():\n",
    "            if x < 300:\n",
    "                finished = False\n",
    "                break\n",
    "        if finished == True:\n",
    "            break\n",
    "    else:\n",
    "        count_dict[curr] = count_dict[curr] + 1\n",
    "        X_temp.append(X_train[i])\n",
    "        y_temp.append(curr)\n",
    "        \n",
    "X_train = np.array(X_temp)\n",
    "y_train = np.array(y_temp)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/carlweilguny/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='logs', histogram_freq=1,\n",
    "                         write_graph=True,\n",
    "                         write_grads=True,\n",
    "                         batch_size=100,\n",
    "                         write_images=True)\n",
    "\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "opt = SGD(lr=0.001, momentum=0.9, clipvalue=5)\n",
    "\n",
    "num_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge inputs and targets\n",
    "Xs = np.concatenate((X_train, X_val), axis=0)\n",
    "ys = np.concatenate((y_train, y_val), axis=0)\n",
    "Xs = X_train\n",
    "ys = y_train\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1, 227, 227)\n"
     ]
    }
   ],
   "source": [
    "print(Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/carlweilguny/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "(2400, 1, 227, 227)\n",
      "(2400,)\n",
      "Train on 1920 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1920/1920 [==============================] - 3889s 2s/sample - loss: 2.4047 - acc: 0.0979 - val_loss: 2.3034 - val_acc: 0.1083\n",
      "Epoch 2/100\n",
      "1920/1920 [==============================] - 3241s 2s/sample - loss: 2.3078 - acc: 0.0974 - val_loss: 2.3031 - val_acc: 0.0938\n",
      "Epoch 3/100\n",
      "1920/1920 [==============================] - 3584s 2s/sample - loss: 2.3030 - acc: 0.1057 - val_loss: 2.3021 - val_acc: 0.1000\n",
      "Epoch 4/100\n",
      "1920/1920 [==============================] - 3377s 2s/sample - loss: 2.3029 - acc: 0.0974 - val_loss: 2.3023 - val_acc: 0.1042\n",
      "Epoch 5/100\n",
      "1920/1920 [==============================] - 3388s 2s/sample - loss: 2.3021 - acc: 0.0969 - val_loss: 2.3018 - val_acc: 0.1083\n",
      "Epoch 6/100\n",
      "1920/1920 [==============================] - 3870s 2s/sample - loss: 2.3018 - acc: 0.1078 - val_loss: 2.3013 - val_acc: 0.1187\n",
      "Epoch 7/100\n",
      "1920/1920 [==============================] - 4023s 2s/sample - loss: 2.3011 - acc: 0.1297 - val_loss: 2.3006 - val_acc: 0.1792\n",
      "Epoch 8/100\n",
      "1920/1920 [==============================] - 3555s 2s/sample - loss: 2.3005 - acc: 0.1255 - val_loss: 2.3001 - val_acc: 0.1896\n",
      "Epoch 9/100\n",
      "1888/1920 [============================>.] - ETA: 45s - loss: 2.2996 - acc: 0.1467 "
     ]
    }
   ],
   "source": [
    "#K.clear_session()\n",
    "model = build_cnn()\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath = \"logs/epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "for train,val in kfold.split(Xs, ys):\n",
    "    print(Xs[train].shape)\n",
    "    print(ys[train].shape)\n",
    "    training_history = model.fit(Xs[train], ys[train], epochs=100, validation_split=0.2, callbacks=[earlyStopping, tbCallBack], shuffle=False)\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(Xs[val], ys[val], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "val_scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
