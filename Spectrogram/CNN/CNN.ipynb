{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from tensorflow import keras\n",
    "### hack tf-keras to appear as top level keras\n",
    "import sys\n",
    "sys.modules['keras'] = keras\n",
    "### end of hack\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, callbacks\n",
    "from keras.callbacks import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import pprint\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "\n",
    "# Importing custom framework\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from data_split import prepare_data_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(227, (3, 1), activation='relu', input_shape=(227, 227, 1)))\n",
    "    model.add(layers.MaxPooling2D((3, 1), 2))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 1), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 1), 2))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 1), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 1), 2))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 1), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 1), 2))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 1), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 1), 2))\n",
    "    \n",
    "    #Fully Connected Part\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(1024))#, input_dim=1024\n",
    "    model.add(layers.Dropout(0.5, seed=1337))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.Dense(512))#, input_dim=1024\n",
    "    model.add(layers.Dropout(0.5, seed=1337))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.Dense(10, input_dim=512))\n",
    "    model.add(layers.Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogramPath = '../../merged/spectrogram.hdf5'\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = prepare_data_spectrogram(spectrogramPath, False)\n",
    "X_train = tf.transpose(X_train, [0, 2, 3, 1])\n",
    "X_val = tf.transpose(X_val, [0, 2, 3, 1])\n",
    "X_test = tf.transpose(X_test, [0, 2, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 227, 227, 1)\n"
     ]
    }
   ],
   "source": [
    "# Decrease training data size to make training feasable\n",
    "#X_temp = []\n",
    "#y_temp = []\n",
    "#n = 300\n",
    "#count_dict = dict.fromkeys(range(0, 10), 0)\n",
    "#for i in range(len(y_train)):\n",
    "#    curr = y_train[i]\n",
    "#    if count_dict[curr] >= n:\n",
    "#        finished = True\n",
    "#        for x in count_dict.values():\n",
    "#            if x < 300:\n",
    "#                finished = False\n",
    "#                break\n",
    "#        if finished == True:\n",
    "##            break\n",
    "#    else:\n",
    "#        count_dict[curr] = count_dict[curr] + 1\n",
    "#        X_temp.append(X_train[i])\n",
    "#        y_temp.append(curr)\n",
    "        \n",
    "#X_train = np.array(X_temp)\n",
    "#y_train = np.array(y_temp)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    }
   ],
   "source": [
    "#tf.reset_default_graph()\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='logs', histogram_freq=1,\n",
    "                         write_graph=True,\n",
    "                         write_grads=True,\n",
    "                         write_images=True)\n",
    "\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "opt = SGD(lr=0.001, momentum=0.9, clipvalue=5)\n",
    "\n",
    "num_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "450/450 [==============================] - 867s 2s/step - loss: 2.3198 - accuracy: 0.1117 - val_loss: 2.2989 - val_accuracy: 0.2236\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 863s 2s/step - loss: 2.2930 - accuracy: 0.1640 - val_loss: 2.2649 - val_accuracy: 0.1508\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 864s 2s/step - loss: 2.1656 - accuracy: 0.2130 - val_loss: 1.7787 - val_accuracy: 0.4314\n",
      "Epoch 4/100\n",
      "321/450 [====================>.........] - ETA: 3:49 - loss: 1.7915 - accuracy: 0.3695"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = build_cnn()\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath = \"logs/epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "training_history = model.fit(X_train, y_train, epochs=100, validation_split=0.2,batch_size=32, callbacks=[earlyStopping, tbCallBack], shuffle=False)\n",
    "# Generate generalization metrics\n",
    "scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'Score {scores}')\n",
    "\n",
    "    \n",
    "#val_scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "#print(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
